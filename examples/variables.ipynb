{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f78007-a4a6-4cf1-8176-e6d8428edfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install promptsite langchain langchain_community openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963679a-88d3-4c0c-9649-33205f6c3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from promptsite.model.variable import ArrayVariable\n",
    "from promptsite.decorator import tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d9e56-a6d7-4024-bc8c-3474f5e7e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=\"your open ai key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebde6c-f011-475c-abd9-9223c6634a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input model\n",
    "class SupportTicket(BaseModel):\n",
    "    ticket_id: str = Field(..., description=\"Unique ticket identifier\")\n",
    "    customer_type: str = Field(..., enum=[\"free\", \"premium\", \"enterprise\"])\n",
    "    category: str = Field(..., enum=[\n",
    "        \"billing\",\n",
    "        \"technical\",\n",
    "        \"feature_request\",\n",
    "        \"account_access\",\n",
    "        \"bug_report\"\n",
    "    ])\n",
    "    message: str = Field(..., description=\"Customer's message\")\n",
    "    language: str = Field(..., enum=[\"en\", \"es\", \"fr\", \"de\"], description=\"Preferred language\")\n",
    "    previous_contacts: int = Field(..., description=\"Number of previous contacts\", ge=0)\n",
    "\n",
    "# define output model\n",
    "class TicketResponse(BaseModel):\n",
    "    ticket_id: str = Field(..., description=\"ID of the ticket being responded to\")\n",
    "    priority: str = Field(..., enum=[\"High\", \"Medium\", \"Low\"])\n",
    "    response: str = Field(..., description=\"Main response message in customer's language\")\n",
    "    next_steps: List[str] = Field(..., description=\"List of next steps or actions\")\n",
    "    documentation: str = Field(..., description=\"Relevant documentation links\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e22f654-d5d7-44fb-b9a7-b99a8902e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Generate appropriate customer support responses for the following tickets:\n",
    "\n",
    "{{ tickets }}\n",
    "\n",
    "For each ticket, provide:\n",
    "1. A response in the customer's preferred language\n",
    "2. Suggested next steps or resolution path\n",
    "3. Any relevant documentation links\n",
    "4. Priority level (High/Medium/Low)\n",
    "\n",
    "Guidelines:\n",
    "- Match tone to customer tier (formal for enterprise, friendly for others)\n",
    "- Acknowledge repeat contacts with extra attention\n",
    "- Include relevant policy information for billing issues\n",
    "- Reference specific parts of their message\n",
    "\n",
    "\n",
    "{{ output }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2b1fa-8a12-4eaa-87fa-c77e47564b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage with tracker decorator\n",
    "@tracker(\n",
    "    prompt_id=\"support_response_generator\",\n",
    "    description=\"Generates customer support responses based on ticket information\",\n",
    "    tags=[\"customer_support\", \"multilingual\"],\n",
    "    variables={\n",
    "        \"tickets\": ArrayVariable(model=SupportTicket), \n",
    "        \"output\": ArrayVariable(model=TicketResponse, is_output=True)\n",
    "    }\n",
    ")\n",
    "def generate_support_responses(content: str, llm_config: dict = {}, **kwargs):\n",
    "    llm = ChatOpenAI(**llm_config)\n",
    "    \n",
    "    # Get response from LLM\n",
    "    response = llm.invoke(content)\n",
    "    \n",
    "    # Return the response string\n",
    "    return response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51833d-e2fb-41ff-9fe2-46013733fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets = [\n",
    "    {\n",
    "        \"ticket_id\": \"T-1001\",\n",
    "        \"customer_type\": \"enterprise\",\n",
    "        \"category\": \"technical\",\n",
    "        \"message\": \"API endpoints returning 503 errors for last 30 minutes\",\n",
    "        \"language\": \"en\",\n",
    "        \"previous_contacts\": 0\n",
    "    },\n",
    "    {\n",
    "        \"ticket_id\": \"T-1003\",\n",
    "        \"customer_type\": \"premium\",\n",
    "        \"category\": \"feature_request\",\n",
    "        \"message\": \"Can you add dark mode to the dashboard?\",\n",
    "        \"language\": \"en\",\n",
    "        \"previous_contacts\": 1\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = generate_support_responses(\n",
    "    content=template,\n",
    "    variables={\"tickets\": tickets},\n",
    "    llm_config={\n",
    "        \"model_name\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0,\n",
    "        \"request_timeout\": 100\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
